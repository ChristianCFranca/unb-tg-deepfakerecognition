{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar algumas arquiteturas que foram treinadas e vamos testá-las no dataset de vídeos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar um modelo resnet18 testado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "in_features = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(in_features, 2)\n",
    "\n",
    "resnet18.load_state_dict(torch.load('./Saved Models/resnet18_balanced_unfreezed_F97_R97_A97.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Definimos um device onde os tensors estarão sendo processados\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dfdc_train_part_0',\n",
       " 'dfdc_train_part_1',\n",
       " 'dfdc_train_part_10',\n",
       " 'dfdc_train_part_11',\n",
       " 'dfdc_train_part_12']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria uma lista de todas as pastas disponíveis para treinamento\n",
    "folders = next(os.walk('./Kaggle Dataset/'))[1]\n",
    "folders[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Videos():\n",
    "    def __init__(self, folder_path):\n",
    "        # Guarda o folder_path\n",
    "        self.folder_path = folder_path\n",
    "        \n",
    "        # Guarda a lista de todos os arquivos de videos dentro do folder_path\n",
    "        self.video_files = glob.glob(folder_path + '/*.mp4')\n",
    "        \n",
    "        # Lê o arquivo JSON que contém as informações dos deepfakes naquela pasta\n",
    "        self.metadata = pd.read_json(folder_path + '/metadata.json').transpose() # Essa transposiçao eh feita pois as colunas e as linhas estao trocadas\n",
    "        \n",
    "    def getRandomVideo(self):\n",
    "        video_path = random.choice(self.video_files)\n",
    "        video_name = os.path.basename(video_path)\n",
    "        label = self.metadata.loc[video_name].label\n",
    "        \n",
    "        return video_path, video_name, label\n",
    "        \n",
    "    def getRealVideo(self, video_name):\n",
    "        real_video_name = self.metadata.loc[video_name].original\n",
    "        # Verifica se é NaN, pois caso seja o nome original é o próprio video real\n",
    "        if pd.isna(real_video_name):\n",
    "            real_video_name = video_name\n",
    "        real_video_path = folder_path + '/' + real_video_name\n",
    "        return real_video_path, real_video_name\n",
    "    \n",
    "    def getAllVideosPath(self):\n",
    "        for video_name, columns in self.metadata.iterrows():\n",
    "            yield self.folder_path + '/' + video_name, video_name, columns[0] # Label\n",
    "\n",
    "def showVideo(video_path, label):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Configura a cor a ser colocada na LABEL\n",
    "    if label == 'REAL':\n",
    "        color = (0, 255, 0) # Verde\n",
    "    else:\n",
    "        color = (0, 0, 255) # Vermelho    \n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            boxes, _ = mtcnn.detect(Image.fromarray(frame))\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color=[0, 255, 0], thickness=5)\n",
    "                    # Escreve a label no vídeo sob a cabeça do indivíduo\n",
    "                    cv2.putText(img=frame, text=label, org=(box[0], box[1]), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=color, thickness=2)\n",
    "\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            cv2.imshow('frame', frame)\n",
    "            #cv2.waitKey(10)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def showAndPredictVideo(video_path, label, padding=0, size=224, check_every_frame=15):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    face = None\n",
    "    video_frame = 1\n",
    "    \n",
    "    # Configura a cor a ser colocada na LABEL\n",
    "    if label == 'REAL':\n",
    "        color = (0, 255, 0) # Verde\n",
    "    else:\n",
    "        color = (0, 0, 255) # Vermelho    \n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            if video_frame == 1 or video_frame % check_every_frame == 0:\n",
    "                boxes = None\n",
    "                boxes, _ = mtcnn.detect(Image.fromarray(frame))\n",
    "                if boxes is not None:\n",
    "                    for box in boxes: \n",
    "                        face = frame[\n",
    "                            int(max(box[1] - padding, 0)):int(max(box[3] + padding, 0)), \n",
    "                            int(max(box[0] - padding, 0)):int(max(box[2] + padding, 0))\n",
    "                        ]\n",
    "                        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color=[0, 255, 0], thickness=5)\n",
    "                    face_tensor = getYUVTensor(face, size, transform)\n",
    "                    cv2.putText(img=frame, text=label, org=(box[0], box[1]), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=color, thickness=2)\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            cv2.imshow('frame', frame)\n",
    "            video_frame += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return face_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.1000, 0.4000],\n",
       "         [0.6000, 0.1000, 0.9000],\n",
       "         [0.8000, 0.3000, 0.7000]],\n",
       "\n",
       "        [[0.5000, 0.1000, 0.4000],\n",
       "         [0.6000, 0.1000, 0.9000],\n",
       "         [0.8000, 0.3000, 0.7000]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[[0.5, 0.1, 0.4],\n",
    "                      [0.6, 0.1, 0.9],\n",
    "                      [0.8, 0.3, 0.7]]])\n",
    "torch.cat((test,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYUVTensor(face, size, transform):\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2YCrCb)\n",
    "    face = cv2.resize(face, (size, size))[:, :, 0]\n",
    "    face_tensor = transform(face)\n",
    "    face_tensor = torch.cat((face_tensor, face_tensor, face_tensor))\n",
    "    return face_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos a coleta de uma pasta aleatória\n",
    "import random\n",
    "random_folder = random.choice(folders) + '/'\n",
    "\n",
    "folder_path = './Kaggle Dataset/' + random_folder\n",
    "\n",
    "# Instaciamos uma classe de Videos\n",
    "videos = Videos(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=False, device=device, thresholds=[0.68, 0.78, 0.78], min_face_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_generator = videos.getAllVideosPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1765, 0.1765, 0.1765,  ..., 0.1843, 0.1882, 0.1922],\n",
       "          [0.1765, 0.1765, 0.1765,  ..., 0.1882, 0.1922, 0.1922],\n",
       "          [0.1804, 0.1765, 0.1765,  ..., 0.1922, 0.1922, 0.1922],\n",
       "          ...,\n",
       "          [0.1882, 0.1882, 0.1882,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.1843, 0.1843, 0.1882,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.1843, 0.1843, 0.1882,  ..., 0.0196, 0.0196, 0.0196]],\n",
       " \n",
       "         [[0.1765, 0.1765, 0.1765,  ..., 0.1843, 0.1882, 0.1922],\n",
       "          [0.1765, 0.1765, 0.1765,  ..., 0.1882, 0.1922, 0.1922],\n",
       "          [0.1804, 0.1765, 0.1765,  ..., 0.1922, 0.1922, 0.1922],\n",
       "          ...,\n",
       "          [0.1882, 0.1882, 0.1882,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.1843, 0.1843, 0.1882,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.1843, 0.1843, 0.1882,  ..., 0.0196, 0.0196, 0.0196]],\n",
       " \n",
       "         [[0.1765, 0.1765, 0.1765,  ..., 0.1843, 0.1882, 0.1922],\n",
       "          [0.1765, 0.1765, 0.1765,  ..., 0.1882, 0.1922, 0.1922],\n",
       "          [0.1804, 0.1765, 0.1765,  ..., 0.1922, 0.1922, 0.1922],\n",
       "          ...,\n",
       "          [0.1882, 0.1882, 0.1882,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.1843, 0.1843, 0.1882,  ..., 0.0196, 0.0196, 0.0196],\n",
       "          [0.1843, 0.1843, 0.1882,  ..., 0.0196, 0.0196, 0.0196]]]),\n",
       " torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path, video_name, label = next(videos_generator)\n",
    "face_tensor = showAndPredictVideo(video_path, label, padding=10, size=224, check_every_frame=1)\n",
    "face_tensor, face_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path, video_name, label = next(videos_generator)\n",
    "showVideo(video_path, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
