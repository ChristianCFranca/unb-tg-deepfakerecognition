{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção automátia de *DeepFakes*\n",
    "## Uma abordagem utilizando redes neurais\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visão Geral do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que afinal é um DeepFake?\n",
    "- A grosso modo é uma técnica utilizada para produzir imagens e **sons** humanos realistas utilizando Deep Learning (origem do 'Deep' no nome).\n",
    "\n",
    "<img src=\"./Imagens/deepfake-example.gif\" width=\"500\" height=\"600\"/>\n",
    "\n",
    "#### Acessibilidade x Resultados\n",
    "O grande problema que está associado ao DeepFake hoje é a relação acessibilidade x resultados. Antigamente, para se produzir um Deepfake, era necessário equipamento/software de ponta, muito talento artístico para tal e processamento computacional ainda muito inacessível. Eram poucas pessoas. O que foi alterado nessa equação nos dias de hoje?\n",
    "\n",
    "- ~TALENTO~\n",
    "\n",
    "Hoje temos a ascenção da inteligência artificial na forma de GANs (Generative Adversarial Network). A compactação e eventual produção em massa dessa arquitetura aplicada à codificação e decodificação de rostos removeu da equação a necessidade de um elevado talento humano para a produção de Deepfakes realistas. GANs são entidades extremamente poderosas capazes de produzir imagens extremamente realistas e que muitas vezes enganam a visão humana. Tudo que elas precisam é dados para treinamento na forma de duas entradas: o rosto/som que se deseja ser trocado e o rosto/som original que deve ser substituído.\n",
    "\n",
    "- ~DIFÍCIL ACESSIBILIDADE~\n",
    "\n",
    "Hoje, com essa ascenção, não mais é necessário um estúdio ou equipamento de ponta para a produção de Deepfakes. A fácil compressão dessas arquiteturas de rede torna possível sua produção em APPs de smartphone e softwares simples de computadores pessoais. Coisas que todos nós temos acesso hoje.\n",
    "\n",
    "Apps chineses como ZAO são capazes de produzir deepfakes realistas em questão de segundos (ainda só funciona com vídeos da própria plataforma).\n",
    "\n",
    "<img src=\"./Imagens/zao_ex1.gif\"  width=\"800\" height=\"100\"/>\n",
    "\n",
    "<img src=\"./Imagens/zao_ex2.gif\"  width=\"800\" height=\"100\"/>\n",
    "\n",
    "Um dos softwares mais famosos para isso hoje é o `DeepFaceLab`, que requer apenas uma instalação simples de windows.\n",
    "\n",
    "<img src=\"./Imagens/DeepFaceLab.PNG\"/>\n",
    "\n",
    "- ~HARDWARE DE PONTA~\n",
    "\n",
    "Como essas arquiteturas muitas vezes podem conter milhões de parâmetros que basicamente se resumem no final a serem utilizados em matrizes que serão multiplicadas (contas simples, milhões delas), a capacidade de uma máquina paralelizar esse treinamento da rede se torna extremamente necessário. Hoje, com o forte mercado de placas gráficas para jogos constantemente em ascenção e o interesse em alta a todo momemnto, temos acesso à placas gráficas extremamente eficientes no treinamento destas redes por um preço bem acessível.\n",
    "\n",
    "#### Qual o problema?\n",
    "Como agora temos uma tecnologia extremamente poderosa na produção de deepfakes e extremamente acessível, temos uma quantidade significativa de pessoas utilizando essa tecnologia para fins maliciosos. Não é incomum achar hoje vídeos de pessoas como Mark Zuckerberg falando coisas que nunca falaria, quando na verdade aquilo é um deepfake realizado por um entusiasta qualquer no computador de casa.\n",
    "\n",
    "<img src=\"./Imagens/mzdf.gif\"/>\n",
    "\n",
    "Isso traz o problema do até quanto será possível obter uma informação virtual e ter certeza que aquela informação é verídica? Hoje já batemos nessa barreira.\n",
    "\n",
    "#### Exemplo de facilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Objetivos Principais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Queremos ser capazes de detectar se algum vídeo em questão contém a presença de DeepFakes faciais (seja de 1 rosto ou vários rostos) utilizando modelos pré treinados no ImageNET e disponíveis no framework Pytorch através da biblioteca FastAI.\n",
    "- Explorar componentes de luminância para ajudar no treinamento das redes.\n",
    "- Observar o quão benéfico é ou não é utilizar essa técnica em relação a técnicas e soluções já propostas na área.\n",
    "- Observar caminhos para a colocação em produção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Base de Dados\n",
    "\n",
    "Sabemos que redes neurais são mapeadores universais de A -> B:\n",
    "\n",
    "- Animal -> É um cachorro? (classificação)\n",
    "- Dados -> Ações vão subir? (classificação)\n",
    "- Paciente -> Dosagem ideal (regressão)\n",
    "\n",
    "Na abordagem que será adotada em questão:\n",
    "- Vídeo -> Contém deepfake? (classificação)\n",
    "\n",
    "Estamos lidando a primeiro momento com um problema de classificação supervisionado. Precisamos de dados:\n",
    "\n",
    "<img src=\"./Imagens/kaggledfdc.PNG\"/>\n",
    "\n",
    "Dataset extenso de aproximadamente `500GB` organizado em `50 pastas`, cada uma contendo `milhares` de vídeos (1000 ~ 3000 vídeo por pasta).\n",
    "\n",
    "- A proporção de vídeos FAKE para vídeos REAL é de 5:1 por pasta, aproximadamente.\n",
    "- As classes de cada vídeos estão organizadas por um arquivo `metadata.JSON` presente em cada uma das postas, controlando os vídeos daquela pasta em particular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Metodologia\n",
    "\n",
    "A abordagem aqui empregada consiste em X etapas:\n",
    "\n",
    "**1.** A primeira parte será extrair os rostos de todos os vídeos de todas as pastas utilizando alguma estratégia e organizá-los em 2 novas pastas: `FAKE` e `REAL`.\n",
    "\n",
    "**2.** Utilizando essas duas novas pastas FAKE e REAL, separar as imagens em `treino`, `validação` e `teste` utilizando `Validação Cruzada` 5 folds.\n",
    "\n",
    "**3.** Carregar as redes pré treinadas disponíveis no Pytorch (Resnets 18 a 50, EfficientNet).\n",
    "\n",
    "**4.** Define-se as características de treinamento e os hiperparâmetros:\n",
    "\n",
    "- Tamanho da imagem.\n",
    "- Tamanho do batch.\n",
    "- Função de custo que queremos minimizar e seus hiperparâmetros.\n",
    "- Métrica para o treinamento e a validação.\n",
    "- Otimizador.\n",
    "- LR scheduler.\n",
    "- Dropout.\n",
    "- Momentum.\n",
    "- Política de aprendizagem.\n",
    "- Callbacks (interromper caso a métrica não melhores / salvar o melhor modelo).\n",
    "\n",
    "**5.** Treinar cada modelo com os hiperparâmetros definidos sob todos os folds e observar a métrica em questão (exemplo: acurácia), tendo então uma ideia da performance esperada para essa aborgadem.\n",
    "\n",
    "**6.** Encontrando um bom balanço de hiperparâmetros e noção de performance para cada modelo, treinar cada modelo novamente do dataset completo e verificar sua performance final no conjunto de `teste`.\n",
    "\n",
    "**7.** Encontrando um bom balanço de hiperparâmetros e noção de performance para cada modelo, treinar cada modelo novamente do dataset completo e verificar sua performance final no conjunto de `teste`.\n",
    "\n",
    "**8.** Definimos uma estratégia para a classificação final individual de cada vídeo e aplicamos os modelos finais gerados x frames a x frames no dataset de vídeos.\n",
    "\n",
    "**9.** Analisamos os resultados para cada modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
