{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este notebook tem como função criar uma pasta chamada \"Kaggle Faces Dataset\" onde os rostos recortados dos vídeos serão guardados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, carregamos as dependências necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define-se o device onde será rodada a detecção de rostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0, GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "# Definimos um device onde os tensores estarão sendo processados\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}, {}'.format(device, torch.cuda.get_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hsypgwsufp.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>nbnipejygk.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntzgbkzofo.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>cqlarprtdy.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ataulynpgd.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>test</td>\n",
       "      <td>uzrkbzwdvi.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idzntwkkjy.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>lvnjzrvzwy.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdqokuannd.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>mujubwlspn.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fseamiushb.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kghcxtmytq.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>cnrqyitpqs.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mzecordeuu.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>dzochfswby.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkwicglevl.mp4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gdhlrzpxxr.mp4</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qgfxkgofjl.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  split        original\n",
       "hsypgwsufp.mp4  FAKE  train  nbnipejygk.mp4\n",
       "ntzgbkzofo.mp4  FAKE  train  cqlarprtdy.mp4\n",
       "ataulynpgd.mp4  FAKE   test  uzrkbzwdvi.mp4\n",
       "idzntwkkjy.mp4  FAKE  train  lvnjzrvzwy.mp4\n",
       "rdqokuannd.mp4  FAKE  train  mujubwlspn.mp4\n",
       "...              ...    ...             ...\n",
       "fseamiushb.mp4  REAL  train            None\n",
       "kghcxtmytq.mp4  FAKE  train  cnrqyitpqs.mp4\n",
       "mzecordeuu.mp4  FAKE  train  dzochfswby.mp4\n",
       "bkwicglevl.mp4  REAL  train            None\n",
       "gdhlrzpxxr.mp4  FAKE  train  qgfxkgofjl.mp4\n",
       "\n",
       "[3192 rows x 3 columns]"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_json(folder/\"metadata.json\").transpose()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1° passo: Criar uma classe que cuida de todas as leituras dos vídeos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria-se uma classe que cuida da leitura de todos os vídeos do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuida de lidar com o acesso aos vídeos e devolver os paths / labels corretamente\n",
    "class Videos():\n",
    "    def __init__(self, root=\"./Kaggle Dataset\"):\n",
    "        # Guarda o folder_path\n",
    "        self.root = Path(root)\n",
    "        \n",
    "        folders = list(self.root.glob(\"*\"))\n",
    "        order = lambda x: int(x.stem.split(\"_\")[-1])\n",
    "        self.folders = sorted(folders, key=order)\n",
    "        \n",
    "    def getRandomVideo(self):\n",
    "        # Lê o arquivo JSON que contém as informações dos deepfakes naquela pasta\n",
    "        \n",
    "        folder_path = random.choice(self.folders)\n",
    "        \n",
    "        metadata = pd.read_json(folder_path/'metadata.json').transpose() # Troca colunas e linhas para ficarEM no formato correto\n",
    "        \n",
    "        video_path = random.choice(list(folder_path)) # Devolve um WindowsPath\n",
    "        \n",
    "        video_name = video_path.name # videoaleatorio.mp4\n",
    "        \n",
    "        label = metadata.loc[video_name].label\n",
    "        \n",
    "        return video_path, video_name, label\n",
    "    \n",
    "    def getRandomLabeledVideo(self, label):\n",
    "        if label not in [\"FAKE\", \"REAL\"]:\n",
    "            print(\"Label deve ser FAKE ou REAL\")\n",
    "            return\n",
    "        \n",
    "        folder_path = random.choice(self.folders) # \"./Kaggle Dataset/some_folder\"\n",
    "        \n",
    "        metadata = pd.read_json(folder_path/'metadata.json').transpose() # Troca colunas e linhas para ficarEM no formato correto\n",
    "        \n",
    "        fake_videos = metadata[metadata.label == label].index # Filtra os videos que são FAKE\n",
    "\n",
    "        video_path = folder_path/random.choice(fake_videos)\n",
    "        \n",
    "        video_name = video_path.name # videoaleatorio.mp4\n",
    "        \n",
    "        label = label\n",
    "        \n",
    "        return video_path, video_name, label\n",
    "        \n",
    "    def getEquivalentRealVideo(self, video_path):\n",
    "        \n",
    "        if not isinstance(video_path, pathlib.WindowsPath):\n",
    "            video_path = Path(video_path)\n",
    "            if not video_path.exists():\n",
    "                print(\"Video path não existe.\")\n",
    "                return\n",
    "            \n",
    "        folder_path = video_path.parent\n",
    "        \n",
    "        metadata = pd.read_json(folder_path/'metadata.json').transpose() # Troca colunas e linhas para ficarEM no formato correto\n",
    "        \n",
    "        try: \n",
    "            video = metadata.loc[video_path.name]\n",
    "        except:\n",
    "            print(\"O vídeo indicado não existe no metadata.\")\n",
    "            return\n",
    "        \n",
    "        if video.label == \"REAL\":\n",
    "            print(\"O vídeo em questão já é um vídeo real.\")\n",
    "            return\n",
    "        \n",
    "        real_video_name = video.original\n",
    "        real_video_path = folder_path.joinpath(real_video_name)\n",
    "        label = \"REAL\"\n",
    "        \n",
    "        return real_video_path, real_video_name, label\n",
    "    \n",
    "    def getAllVideosPath(self):\n",
    "        for video_name, columns in self.metadata.iterrows():\n",
    "            yield self.folder_path + '/' + video_name, video_name, columns[0] # Label\n",
    "            \n",
    "    def generateMetadataTestSplit(self, proportion=0.2): # 20% para o set de treinamento\n",
    "        print(\"Ajuste de metadata.json em andamento...\")\n",
    "        np.random.seed(42)\n",
    "        for folder in self.folders:\n",
    "            metadata_path = folder/\"metadata.json\"\n",
    "            metadata = pd.read_json(metadata_path).transpose()\n",
    "            if \"test\" not in metadata.values:\n",
    "                counts = metadata.label.value_counts()\n",
    "\n",
    "                reals_quantity_to_test = int(proportion*counts[\"REAL\"])\n",
    "                fakes_quantity_to_test = int(proportion*counts[\"FAKE\"])\n",
    "\n",
    "                real_videos = metadata[metadata.label == 'REAL'].index\n",
    "                fake_videos = metadata[metadata.label == 'FAKE'].index\n",
    "\n",
    "                reals_to_test = np.random.choice(real_videos, size=reals_quantity_to_test)\n",
    "                fakes_to_test = np.random.choice(fake_videos, size=fakes_quantity_to_test)\n",
    "\n",
    "                metadata.loc[reals_to_test, 'split'] = \"test\"\n",
    "                metadata.loc[fakes_to_test, 'split'] = \"test\"\n",
    "            else:\n",
    "                print(\"Pass...\")\n",
    "            #metadata.transpose().to_json(metadata_path)\n",
    "        print(\"Finalizado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função **showVideo()**: Mostra o vídeo para checagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showVideo(video_path, resize_factor=0.6):\n",
    "    \n",
    "    # Captura o vídeo no path\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read() # Lê o próximo frame\n",
    "        if ret: # Sucesso na leitura\n",
    "            frame = cv2.resize(frame, (int(frame.shape[1]*resize_factor), int(frame.shape[0]*resize_factor)))\n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            # Apertar a tecla 'q' para sair do vídeo.\n",
    "            key = cv2.waitKey(25)\n",
    "            if key == 113:\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showVideoWithDetection(video_path, label=None, padding=0, size=-1, separate_face_box=False, resize_factor=0.6):\n",
    "    \n",
    "    # Captura o vídeo no path\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    \n",
    "    # Configura a cor a ser colocada na LABEL\n",
    "    if label == 'REAL':\n",
    "        color = (0, 255, 0) # Verde\n",
    "    elif label == \"FAKE\":\n",
    "        color = (0, 0, 255) # Vermelho  \n",
    "    else:\n",
    "        color = (0, 255, 255)\n",
    "    \n",
    "    face = None\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read() # Lê o próximo frame\n",
    "        if ret: # Sucesso na leitura\n",
    "            boxes, _ = mtcnn.detect(Image.fromarray(frame)) # Detecta as imagens. O método detect só aceita numpy arrays\n",
    "            if boxes is not None: # Só entra se rostos forem detectados\n",
    "                for box in boxes: # Para cada uma das bouding boxes encontradas em um único frame (a princípio só deve ter uma)\n",
    "                    box = [int(b) for b in box]\n",
    "                    if separate_face_box:\n",
    "                        face = frame[int(box[1] - padding):int(box[3] + padding), int(box[0] - padding):int(box[2] + padding)].copy()\n",
    "                        if face is not None:\n",
    "                            if size > 0:\n",
    "                                face = cv2.resize(face, (size, size))\n",
    "                            cv2.imshow('face', face)\n",
    "                    cv2.putText(img=frame, text=label, org=(box[0], box[1]), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=color, thickness=2)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color=[0, 255, 0], thickness=5)\n",
    "\n",
    "            frame = cv2.resize(frame, (int(frame.shape[1]*resize_factor), int(frame.shape[0]*resize_factor)))\n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            # Apertar a tecla 'q' para sair do vídeo.\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2° passo: Observar alguns vídeos e ajustar o threshold do MTCNN para a detecção de rostos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MTCNN** - *Multi-task Cascaded Convolutional Network*\n",
    "\n",
    "Ajustamos os thresholds e utilizamos a função de mostrar os vídeos, verificando visualmente se ele se comporta bem na maioria dos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margin não faz diferença se o método .detect() for utilizado\n",
    "IMAGE_SIZE = 224\n",
    "MARGIN = 0\n",
    "MIN_FACE_SIZE = 90\n",
    "THRESHOLDS = [0.68, 0.75, 0.80]\n",
    "POST_PROCESS = False\n",
    "SELECT_LARGEST = True\n",
    "KEEP_ALL = False\n",
    "DEVICE = device\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "mtcnn = MTCNN(image_size=IMAGE_SIZE,\n",
    "              margin=MARGIN, \n",
    "              min_face_size=MIN_FACE_SIZE, \n",
    "              thresholds=THRESHOLDS,\n",
    "              post_process=POST_PROCESS,\n",
    "              select_largest=SELECT_LARGEST, \n",
    "              keep_all=KEEP_ALL, \n",
    "              device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objeto Videos\n",
    "\n",
    "Definimos nosso objeto vídeos com o diretório onde contém as pastas do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instaciamos uma objeto da classe Videos\n",
    "videos = Videos(root=\"./Kaggle Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vídeo Real Aleatório\n",
    "\n",
    "Para cancelar a visualização do vídeo em tempo real, apertar a tecla `q` do teclado.Para cancelar a visualização do vídeo em tempo real, apertar a tecla `q` do teclado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path, video_name, label = videos.getRandomLabeledVideo(label=\"REAL\")\n",
    "\n",
    "# Podemos passar um padding para verificar a quantidade desejada de recorte ao redo do rosto detectado\n",
    "showVideo(video_path)\n",
    "showVideoWithDetection(video_path, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vídeo Falso Aleatório\n",
    "\n",
    "Para cancelar a visualização do vídeo em tempo real, apertar a tecla `q` do teclado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path, video_name, label = videos.getRandomLabeledVideo(label=\"FAKE\") # Recupera o caminho de um vídeo aleatório na pasta que esteja com a label 'FAKE'\n",
    "\n",
    "showVideo(video_path)\n",
    "showVideoWithDetection(video_path, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vídeo Falso Aleatório e sua versão REAL\n",
    "\n",
    "Para cancelar a visualização do vídeo em tempo real, apertar a tecla `q` do teclado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path, video_name, label = videos.getRandomLabeledVideo(label=\"FAKE\") # Recupera o caminho de um vídeo aleatório na pasta que esteja com a label 'FAKE'\n",
    "video_path_real, video_name_real, label_real = videos.getEquivalentRealVideo(video_path)\n",
    "\n",
    "showVideo(video_path)\n",
    "showVideo(video_path_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudo estando ok, agora podemos separar todos os vídeos em um conjunto de treinamento para realizar a validação cruzada (80%) e um conjunto de vídeo finais para teste (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajuste de metadata.json em andamento...\n",
      "Finalizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "videos.generateMetadataTestSplit(proportion=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3° Passo: Criar uma classe que recebe um vídeo, detecta todos os rostos, rescorta eles e os salva no diretório em questão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe **CropSaver()**: Recorta todos os rostos de um vídeo dada uma taxa de checagem por frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropSaver(Videos):\n",
    "    \n",
    "    def __init__(self, root=\"./Kaggle Dataset\"):\n",
    "        super().__init__(root)\n",
    "        # Instaciamos a MTCNN de forma interna\n",
    "        IMAGE_SIZE = 224\n",
    "        MARGIN = 0\n",
    "        MIN_FACE_SIZE = 90\n",
    "        THRESHOLDS = [0.68, 0.75, 0.80]\n",
    "        POST_PROCESS = False\n",
    "        SELECT_LARGEST = True\n",
    "        KEEP_ALL = False\n",
    "        DEVICE = device\n",
    "\n",
    "        # ----------------------------------\n",
    "\n",
    "        self.mtcnn = MTCNN(image_size=IMAGE_SIZE,\n",
    "                      margin=MARGIN, \n",
    "                      min_face_size=MIN_FACE_SIZE, \n",
    "                      thresholds=THRESHOLDS,\n",
    "                      post_process=POST_PROCESS,\n",
    "                      select_largest=SELECT_LARGEST, \n",
    "                      keep_all=KEEP_ALL, \n",
    "                      device=device).eval()\n",
    "\n",
    "    def callCropFaces(self, path_to_save=\"./Kaggle Faces Dataset\", call=\"test-video\"):\n",
    "        path_to_save = Path(path_to_save)\n",
    "        if call == \"test-video\":\n",
    "            video_path = list(self.folders[0].glob(\"*.mp4\"))[0]\n",
    "            metadata = pd.read_json(self.folders[0]/\"metadata.json\").transpose()\n",
    "            video_name = video_path.name\n",
    "            label = metadata.loc[video_name].label\n",
    "            split = metadata.loc[video_name].split\n",
    "            print(\"-\"*20 + \"Beggining...\" + \"-\"*20 )\n",
    "            begin = time.time()\n",
    "            self.saveCropFaces(video_path, path_to_save, split, label)\n",
    "            end = time.time()\n",
    "            elapsed = end - begin\n",
    "            print(f\"Iteration Complete | Time elapsed: {elapsed // 60}m{elapsed%60}s\")\n",
    "        elif call == \"test-folder\":\n",
    "            videos_path = list(self.folders[0].glob(\"*.mp4\"))\n",
    "            metadata = pd.read_json(self.folders[0]/\"metadata.json\").transpose()\n",
    "            print(\"-\"*20 + \"Beggining...\" + \"-\"*20 )\n",
    "            begin = time.time()\n",
    "            for video_path in videos_path:\n",
    "                video_name = video_path.name\n",
    "                label = metadata.loc[video_name].label\n",
    "                split = metadata.loc[video_name].split\n",
    "                self.saveCropFaces(video_path, path_to_save, split, label)\n",
    "            end = time.time()\n",
    "            elapsed = end - begin\n",
    "            print(f\"Iteration Complete | Time elapsed: {elapsed // 60}m{elapsed%60}s\")\n",
    "\n",
    "    def saveCropFaces(self, video_path, path_to_save, split, label, batch_size=20, padding=0, size=-1, check_every_frame=30):\n",
    "\n",
    "        # Instancia um VideoCapture do arquivo presente em video_path (no caso, o vídeo)\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        \n",
    "        # Pega, em inteiros, a quantidade de frames do vídeo\n",
    "        v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Cria um path para salvar os rostos recortados do vídeo\n",
    "        class_path = path_to_save.joinpath(split, label) # Path(./Kaggle Faces Dataset/train/FAKE ou REAL)\n",
    "        \n",
    "        if not class_path.exists():\n",
    "            print(f\"The folder {class_path} não é alcançável.\")\n",
    "            return\n",
    "        \n",
    "        # Inicializa frames como uma lista vazia\n",
    "        frames = []\n",
    "        face_count = 0\n",
    "        \n",
    "        # Entra num loop que percorre o vídeo até ele acabar\n",
    "        for _ in range(1, v_len + 1):\n",
    "            # Realiza um grab() no próximo frame, mas não o decodifica. Isso ajuda a agilizar o processo se não for necessário\n",
    "            # recuperar todos os frames a todo o momento.\n",
    "            success = cap.grab()\n",
    "            # Só recorta o rosto se o frame atual for mod check_every_frame, ou seja, ele só decodifica de check_every_frame em check_every_frame frames.\n",
    "            if not success:\n",
    "                continue\n",
    "            if _ == 1 or _ % check_every_frame == 0:\n",
    "                success, frame = cap.retrieve()\n",
    "            else:\n",
    "                continue\n",
    "            if not success:\n",
    "                continue\n",
    "            # Realiza um append do frame atual na lista frames (ele é capturado no formato BGR porém a MTCNN espera no formato RGB)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)\n",
    "            \n",
    "            # Se o tamanho dos frames alcançou o batch_size OU o meu iterador de frames chegou no máixmo juntamento com meu tamanho de frames dentro da lista sendo maior que zero, continua pra capturar o rosto\n",
    "            if len(frames) >= batch_size or (_ == v_len and len(frames) > 0):\n",
    "                # Utiliza o MTCNN para detectar todas as bounding boxes de todos os rostos\n",
    "                boxes, probs = self.mtcnn.detect(frames)\n",
    "                # Verifica se não foi obtida nenhuma bounding box em todo o batch\n",
    "                if not all(x is None for x in boxes):\n",
    "                    # Acessa cada um dos frames no batch\n",
    "                    for i, boxes_f in enumerate(boxes):\n",
    "                        # Verifica houve None para o frame atual\n",
    "                        if boxes_f is not None:\n",
    "                            # Acessa cada uma das bounding boxes dentro de um único frame (pode haver vários rostos)\n",
    "                            for bbox in boxes_f:\n",
    "                                # Obtém o rosto\n",
    "                                face = frames[i].crop(box=(bbox[0]-padding, \n",
    "                                                           bbox[1]-padding, \n",
    "                                                           bbox[2]+padding, \n",
    "                                                           bbox[3]+padding))\n",
    "\n",
    "                                # Se desejado, aplica um resize\n",
    "                                if size > 0:\n",
    "                                    face = face.resize((size, size))\n",
    "                                    \n",
    "                                # face_count serve para não ocorrer sobrescrição de mais de um rosto por frame\n",
    "                                face_count += 1\n",
    "                                \n",
    "                                # Cria o path para o rosto atual\n",
    "                                \n",
    "                                path = class_path.joinpath(f\"{video_path.parts[-2]} {video_path.parts[-1]} {face_count} .jpg\")\n",
    "                                # Salva o rosto na pasta correta.\n",
    "                                face.save(path)\n",
    "\n",
    "                # Após o batch ser aplicado, resetamos a lista\n",
    "                frames = []\n",
    "\n",
    "        # Solta o objeto do VideoCapture\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testamos agora para apenas 1 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropsaver = CropSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Beggining...--------------------\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 1 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 2 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 3 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 4 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 5 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 6 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 7 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 8 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 9 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 10 .jpg\n",
      "Kaggle Faces Dataset\\test\\FAKE\\dfdc_train_part_0 aaqaifqrwn.mp4 11 .jpg\n",
      "Iteration Complete | Time elapsed: 0.0m0.7239961624145508s\n"
     ]
    }
   ],
   "source": [
    "cropsaver.callCropFaces(call=\"test-video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos um loop utilizando a função saveCropFaces, que será chamada uma vez por vídeo. Com isso, esperamos e conferimos a pasta para ver se os arquivos estão corretamente lá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Início do folder dfdc_train_part_0 --------------\n",
      "dfdc_train_part_0: 0.00%...\n",
      "dfdc_train_part_0: 5.00%...\n",
      "dfdc_train_part_0: 10.00%...\n",
      "dfdc_train_part_0: 15.00%...\n",
      "dfdc_train_part_0: 20.00%...\n",
      "dfdc_train_part_0: 25.00%...\n",
      "dfdc_train_part_0: 30.00%...\n",
      "dfdc_train_part_0: 35.00%...\n",
      "dfdc_train_part_0: 40.00%...\n",
      "dfdc_train_part_0: 45.00%...\n",
      "dfdc_train_part_0: 49.00%...\n",
      "dfdc_train_part_0: 54.00%...\n",
      "dfdc_train_part_0: 59.00%...\n",
      "dfdc_train_part_0: 64.00%...\n",
      "dfdc_train_part_0: 69.00%...\n",
      "dfdc_train_part_0: 74.00%...\n",
      "dfdc_train_part_0: 79.00%...\n",
      "dfdc_train_part_0: 84.00%...\n",
      "dfdc_train_part_0: 89.00%...\n",
      "dfdc_train_part_0: 94.00%...\n",
      "Tempo que levou para a conclusão de 1335 vídeos: 21:5 min\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "PADDING = 10\n",
    "SIZE = -1\n",
    "CHECK_EVERY_FRAME = 15\n",
    "CHANNEL = None\n",
    "FOLDER = 'Dataset provisório'\n",
    "SIZE_FOLDER = 'no-resize-color'\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "init = time.time()\n",
    "print(\"-------------- Início do folder {} --------------\".format(folder))\n",
    "videos_quantity = len(videos.video_files)\n",
    "percentage = 5\n",
    "print_every = int(videos_quantity / (100/percentage))\n",
    "    \n",
    "for n_video, VIDEO_DATA in enumerate(videos_generator):\n",
    "    \n",
    "    saveCropFaces(*VIDEO_DATA, \n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  padding=PADDING, \n",
    "                  size=SIZE, \n",
    "                  check_every_frame=CHECK_EVERY_FRAME, \n",
    "                  channel=CHANNEL, \n",
    "                  folder=FOLDER,\n",
    "                  size_folder=SIZE_FOLDER)\n",
    "    \n",
    "    if n_video % print_every == 0:\n",
    "        print(\"{}: {:.2f}%...\".format(folder, round(n_video / videos_quantity * 100)))\n",
    "        \n",
    "end = time.time()\n",
    "total = end - init\n",
    "print(\"Tempo que levou para a conclusão de {} vídeos: {:.0f}:{:.0f} min\".format(len(os.listdir(folder_path)), int(total/60), total % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que demora em torno de 22 minutos para terminar uma pasta. Depende bastante dq uantidade de vídeos na pasta. Podemos aumentar o batch_size para 30 para acelerar o processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4° Passo: Agora, podemos finalmente exportar todo o dataset de vídeos em imagens de rostos. (Pode levar algumas horas para concluir)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nossa MTCNN final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margin não faz diferença se o método .detect() for utilizado\n",
    "IMAGE_SIZE = 224\n",
    "MARGIN = 0\n",
    "MIN_FACE_SIZE = 100\n",
    "THRESHOLDS = [0.78, 0.78, 0.78]\n",
    "POST_PROCESS = False\n",
    "SELECT_LARGEST = False\n",
    "KEEP_ALL = True\n",
    "DEVICE = device\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "mtcnn = MTCNN(image_size=IMAGE_SIZE,\n",
    "              margin=MARGIN, \n",
    "              min_face_size=MIN_FACE_SIZE, \n",
    "              thresholds=THRESHOLDS,\n",
    "              post_process=POST_PROCESS,\n",
    "              select_largest=SELECT_LARGEST, \n",
    "              keep_all=KEEP_ALL, \n",
    "              device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui nós removemos os folder que já foram avaliados em momentos anteriores quando rodou-se o script do código. Para novos foldes será necessário escrever manualmente o nome na lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_folders = ['dfdc_train_part_31', \n",
    "                'dfdc_train_part_10', \n",
    "                'dfdc_train_part_40', \n",
    "                'dfdc_train_part_22', \n",
    "                'dfdc_train_part_41', \n",
    "                'dfdc_train_part_21', \n",
    "                'dfdc_train_part_38', \n",
    "                'dfdc_train_part_36', \n",
    "                'dfdc_train_part_43']\n",
    "\n",
    "recent_folders = [folder for folder in folders if folder not in done_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 16, 15, 26,  4, 12, 37, 27, 39,  6, 25,  9, 13, 31, 34,  8, 17,\n",
       "       24,  0, 33,  5, 11,  1, 29, 21,  2, 30, 36,  3, 35, 23, 32, 10, 22,\n",
       "       18, 20,  7, 14, 28, 38])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_order = np.random.RandomState(seed=42).permutation(len(recent_folders))\n",
    "pick_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E iniciamos o loop que pode levar de algumas horas até alguns dias para terminar, dependendo do hardware. Valores importante que devem ser setados nessa etapa por fim:\n",
    "- `CHECK_EVERY_FRAME`: Define de quantos em quantos frames será realizada a inferência da rede para obter o rosto. Caso o valor seja 1 a rede realizará a inferência de 1 em 1 frame, ou seja, tentará encontrar e recortar os rostos de todos os frames de todos os vídeos.\n",
    "- `PADDING`: Controla a margem de recorte das imagens. Quanto maior este número, maior será a margem em volta do rosto recortado.\n",
    "- `SIZE`: Controla as dimensões de saída do rosto recortado. Caso seja `-1`, o rosto será salvo nas dimensões originais obtidas. Como muitos frameworks de Deep Learning contém transformações do tipo **resize** extremamente otimizados, preferi manter o tamanho originalmente obtido permitindo maior flexibilidade com quem venha a implementar a leitura dessas imagens futuramente.\n",
    "- `BATCH_SIZE`: Controla o tamanho do batch de frames que será processado de uma única vez pela MTCNN. Um maior número significa mais paralelado que significa mais rápido, porém pode ser que a memória dos hardwares não suporte valores muito elevados. Exemplo: Minha RTX 2070 com 8GB de memória suporta um máximo batch_size em torno de 30.\n",
    "- `CHANNEL`: Controla o espaço de cores do rosto recortado. Caso seja `None`, será salva a imagem recortada do rosto com os 3 canais originais RGB. A única outra implementação disponível aqui é `'luma'`, que transforma a imagem para o espaço YCrCb e salva somente o canal Y (luma).\n",
    "- `FOLDER`: Nome da pasta onde estará a subpasta que contenha as pastas \"FAKE\" e \"REAL\".\n",
    "- `SIZE_FOLDER`: Nome da subpasta onde estarão as pastas \"FAKE\" e \"REAL\", que a função utilizará para distribuir as imagens corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Início do folder dfdc_train_part_26 --------------\n",
      "dfdc_train_part_29: 0.00%...\n",
      "dfdc_train_part_29: 25.00%...\n",
      "dfdc_train_part_29: 50.00%...\n",
      "dfdc_train_part_29: 75.00%...\n",
      "dfdc_train_part_29: 100.00%...\n",
      "Tempo para a conclusão do diretório: 40:25 min\n",
      "-------------- Início do folder dfdc_train_part_23 --------------\n",
      "dfdc_train_part_26: 0.00%...\n",
      "dfdc_train_part_26: 25.00%...\n",
      "dfdc_train_part_26: 50.00%...\n",
      "dfdc_train_part_26: 75.00%...\n",
      "dfdc_train_part_26: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:15 min\n",
      "-------------- Início do folder dfdc_train_part_22 --------------\n",
      "dfdc_train_part_25: 0.00%...\n",
      "dfdc_train_part_25: 25.00%...\n",
      "dfdc_train_part_25: 50.00%...\n",
      "dfdc_train_part_25: 75.00%...\n",
      "dfdc_train_part_25: 100.00%...\n",
      "Tempo para a conclusão do diretório: 36:0 min\n",
      "-------------- Início do folder dfdc_train_part_32 --------------\n",
      "dfdc_train_part_37: 0.00%...\n",
      "dfdc_train_part_37: 25.00%...\n",
      "dfdc_train_part_37: 50.00%...\n",
      "dfdc_train_part_37: 75.00%...\n",
      "dfdc_train_part_37: 100.00%...\n",
      "Tempo para a conclusão do diretório: 36:56 min\n",
      "-------------- Início do folder dfdc_train_part_12 --------------\n",
      "dfdc_train_part_13: 0.00%...\n",
      "dfdc_train_part_13: 25.00%...\n",
      "dfdc_train_part_13: 50.00%...\n",
      "dfdc_train_part_13: 75.00%...\n",
      "dfdc_train_part_13: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:27 min\n",
      "-------------- Início do folder dfdc_train_part_2 --------------\n",
      "dfdc_train_part_20: 0.00%...\n",
      "dfdc_train_part_20: 25.00%...\n",
      "dfdc_train_part_20: 50.00%...\n",
      "dfdc_train_part_20: 75.00%...\n",
      "dfdc_train_part_20: 100.00%...\n",
      "Tempo para a conclusão do diretório: 32:21 min\n",
      "-------------- Início do folder dfdc_train_part_42 --------------\n",
      "dfdc_train_part_7: 0.00%...\n",
      "dfdc_train_part_7: 25.00%...\n",
      "dfdc_train_part_7: 50.00%...\n",
      "dfdc_train_part_7: 75.00%...\n",
      "dfdc_train_part_7: 100.00%...\n",
      "Tempo para a conclusão do diretório: 37:58 min\n",
      "-------------- Início do folder dfdc_train_part_33 --------------\n",
      "dfdc_train_part_39: 0.00%...\n",
      "dfdc_train_part_39: 25.00%...\n",
      "dfdc_train_part_39: 50.00%...\n",
      "dfdc_train_part_39: 75.00%...\n",
      "Tempo para a conclusão do diretório: 38:14 min\n",
      "-------------- Início do folder dfdc_train_part_44 --------------\n",
      "dfdc_train_part_9: 0.00%...\n",
      "dfdc_train_part_9: 25.00%...\n",
      "dfdc_train_part_9: 50.00%...\n",
      "dfdc_train_part_9: 75.00%...\n",
      "Tempo para a conclusão do diretório: 26:36 min\n",
      "-------------- Início do folder dfdc_train_part_14 --------------\n",
      "dfdc_train_part_15: 0.00%...\n",
      "dfdc_train_part_15: 25.00%...\n",
      "dfdc_train_part_15: 50.00%...\n",
      "dfdc_train_part_15: 75.00%...\n",
      "dfdc_train_part_15: 100.00%...\n",
      "Tempo para a conclusão do diretório: 32:24 min\n",
      "-------------- Início do folder dfdc_train_part_31 --------------\n",
      "dfdc_train_part_35: 0.00%...\n",
      "dfdc_train_part_35: 25.00%...\n",
      "dfdc_train_part_35: 50.00%...\n",
      "dfdc_train_part_35: 75.00%...\n",
      "dfdc_train_part_35: 100.00%...\n",
      "Tempo para a conclusão do diretório: 36:28 min\n",
      "-------------- Início do folder dfdc_train_part_17 --------------\n",
      "dfdc_train_part_18: 0.00%...\n",
      "dfdc_train_part_18: 25.00%...\n",
      "dfdc_train_part_18: 50.00%...\n",
      "dfdc_train_part_18: 75.00%...\n",
      "dfdc_train_part_18: 100.00%...\n",
      "Tempo para a conclusão do diretório: 37:37 min\n",
      "-------------- Início do folder dfdc_train_part_20 --------------\n",
      "dfdc_train_part_23: 0.00%...\n",
      "dfdc_train_part_23: 25.00%...\n",
      "dfdc_train_part_23: 50.00%...\n",
      "dfdc_train_part_23: 75.00%...\n",
      "dfdc_train_part_23: 100.00%...\n",
      "Tempo para a conclusão do diretório: 36:8 min\n",
      "-------------- Início do folder dfdc_train_part_37 --------------\n",
      "dfdc_train_part_45: 0.00%...\n",
      "dfdc_train_part_45: 25.00%...\n",
      "dfdc_train_part_45: 50.00%...\n",
      "dfdc_train_part_45: 75.00%...\n",
      "dfdc_train_part_45: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:36 min\n",
      "-------------- Início do folder dfdc_train_part_4 --------------\n",
      "dfdc_train_part_48: 0.00%...\n",
      "dfdc_train_part_48: 25.00%...\n",
      "dfdc_train_part_48: 50.00%...\n",
      "dfdc_train_part_48: 75.00%...\n",
      "dfdc_train_part_48: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:47 min\n",
      "-------------- Início do folder dfdc_train_part_16 --------------\n",
      "dfdc_train_part_17: 0.00%...\n",
      "dfdc_train_part_17: 25.00%...\n",
      "dfdc_train_part_17: 50.00%...\n",
      "dfdc_train_part_17: 75.00%...\n",
      "dfdc_train_part_17: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:36 min\n",
      "-------------- Início do folder dfdc_train_part_24 --------------\n",
      "dfdc_train_part_27: 0.00%...\n",
      "dfdc_train_part_27: 25.00%...\n",
      "dfdc_train_part_27: 50.00%...\n",
      "dfdc_train_part_27: 75.00%...\n",
      "dfdc_train_part_27: 100.00%...\n",
      "Tempo para a conclusão do diretório: 31:25 min\n",
      "-------------- Início do folder dfdc_train_part_30 --------------\n",
      "dfdc_train_part_34: 0.00%...\n",
      "dfdc_train_part_34: 25.00%...\n",
      "dfdc_train_part_34: 50.00%...\n",
      "dfdc_train_part_34: 75.00%...\n",
      "dfdc_train_part_34: 100.00%...\n",
      "Tempo para a conclusão do diretório: 39:52 min\n",
      "-------------- Início do folder dfdc_train_part_0 --------------\n",
      "dfdc_train_part_0: 0.00%...\n",
      "dfdc_train_part_0: 25.00%...\n",
      "dfdc_train_part_0: 50.00%...\n",
      "dfdc_train_part_0: 75.00%...\n",
      "dfdc_train_part_0: 100.00%...\n",
      "Tempo para a conclusão do diretório: 21:9 min\n",
      "-------------- Início do folder dfdc_train_part_39 --------------\n",
      "dfdc_train_part_47: 0.00%...\n",
      "dfdc_train_part_47: 25.00%...\n",
      "dfdc_train_part_47: 50.00%...\n",
      "dfdc_train_part_47: 75.00%...\n",
      "dfdc_train_part_47: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:56 min\n",
      "-------------- Início do folder dfdc_train_part_13 --------------\n",
      "dfdc_train_part_14: 0.00%...\n",
      "dfdc_train_part_14: 25.00%...\n",
      "dfdc_train_part_14: 50.00%...\n",
      "dfdc_train_part_14: 75.00%...\n",
      "Tempo para a conclusão do diretório: 38:8 min\n",
      "-------------- Início do folder dfdc_train_part_19 --------------\n",
      "dfdc_train_part_2: 0.00%...\n",
      "dfdc_train_part_2: 25.00%...\n",
      "dfdc_train_part_2: 50.00%...\n",
      "dfdc_train_part_2: 75.00%...\n",
      "Tempo para a conclusão do diretório: 28:51 min\n",
      "-------------- Início do folder dfdc_train_part_1 --------------\n",
      "dfdc_train_part_1: 0.00%...\n",
      "dfdc_train_part_1: 25.00%...\n",
      "dfdc_train_part_1: 50.00%...\n",
      "dfdc_train_part_1: 75.00%...\n",
      "dfdc_train_part_1: 100.00%...\n",
      "Tempo para a conclusão do diretório: 26:38 min\n",
      "-------------- Início do folder dfdc_train_part_35 --------------\n",
      "dfdc_train_part_42: 0.00%...\n",
      "dfdc_train_part_42: 25.00%...\n",
      "dfdc_train_part_42: 50.00%...\n",
      "dfdc_train_part_42: 75.00%...\n",
      "Tempo para a conclusão do diretório: 37:32 min\n",
      "-------------- Início do folder dfdc_train_part_28 --------------\n",
      "dfdc_train_part_30: 0.00%...\n",
      "dfdc_train_part_30: 25.00%...\n",
      "dfdc_train_part_30: 50.00%...\n",
      "dfdc_train_part_30: 75.00%...\n",
      "Tempo para a conclusão do diretório: 34:43 min\n",
      "-------------- Início do folder dfdc_train_part_10 --------------\n",
      "dfdc_train_part_11: 0.00%...\n",
      "dfdc_train_part_11: 25.00%...\n",
      "dfdc_train_part_11: 50.00%...\n",
      "dfdc_train_part_11: 75.00%...\n",
      "dfdc_train_part_11: 100.00%...\n",
      "Tempo para a conclusão do diretório: 31:10 min\n",
      "-------------- Início do folder dfdc_train_part_36 --------------\n",
      "dfdc_train_part_44: 0.00%...\n",
      "dfdc_train_part_44: 25.00%...\n",
      "dfdc_train_part_44: 50.00%...\n",
      "dfdc_train_part_44: 75.00%...\n",
      "dfdc_train_part_44: 100.00%...\n",
      "Tempo para a conclusão do diretório: 39:56 min\n",
      "-------------- Início do folder dfdc_train_part_41 --------------\n",
      "dfdc_train_part_6: 0.00%...\n",
      "dfdc_train_part_6: 25.00%...\n",
      "dfdc_train_part_6: 50.00%...\n",
      "dfdc_train_part_6: 75.00%...\n",
      "Tempo para a conclusão do diretório: 25:25 min\n",
      "-------------- Início do folder dfdc_train_part_11 --------------\n",
      "dfdc_train_part_12: 0.00%...\n",
      "dfdc_train_part_12: 25.00%...\n",
      "dfdc_train_part_12: 50.00%...\n",
      "dfdc_train_part_12: 75.00%...\n",
      "dfdc_train_part_12: 100.00%...\n",
      "Tempo para a conclusão do diretório: 35:28 min\n",
      "-------------- Início do folder dfdc_train_part_40 --------------\n",
      "dfdc_train_part_5: 0.00%...\n",
      "dfdc_train_part_5: 25.00%...\n",
      "dfdc_train_part_5: 50.00%...\n",
      "dfdc_train_part_5: 75.00%...\n",
      "dfdc_train_part_5: 100.00%...\n",
      "Tempo para a conclusão do diretório: 41:22 min\n",
      "-------------- Início do folder dfdc_train_part_3 --------------\n",
      "dfdc_train_part_33: 0.00%...\n",
      "dfdc_train_part_33: 25.00%...\n",
      "dfdc_train_part_33: 50.00%...\n",
      "dfdc_train_part_33: 75.00%...\n",
      "dfdc_train_part_33: 100.00%...\n",
      "Tempo para a conclusão do diretório: 34:16 min\n",
      "-------------- Início do folder dfdc_train_part_38 --------------\n",
      "dfdc_train_part_46: 0.00%...\n",
      "dfdc_train_part_46: 25.00%...\n",
      "dfdc_train_part_46: 50.00%...\n",
      "dfdc_train_part_46: 75.00%...\n",
      "dfdc_train_part_46: 100.00%...\n",
      "Tempo para a conclusão do diretório: 32:13 min\n",
      "-------------- Início do folder dfdc_train_part_18 --------------\n",
      "dfdc_train_part_19: 0.00%...\n",
      "dfdc_train_part_19: 25.00%...\n",
      "dfdc_train_part_19: 50.00%...\n",
      "dfdc_train_part_19: 75.00%...\n",
      "dfdc_train_part_19: 100.00%...\n",
      "dfdc_train_part_19: 125.00%...\n",
      "dfdc_train_part_19: 150.00%...\n",
      "Tempo para a conclusão do diretório: 23:13 min\n",
      "-------------- Início do folder dfdc_train_part_29 --------------\n",
      "dfdc_train_part_32: 0.00%...\n",
      "dfdc_train_part_32: 25.00%...\n",
      "dfdc_train_part_32: 50.00%...\n",
      "dfdc_train_part_32: 75.00%...\n",
      "Tempo para a conclusão do diretório: 37:44 min\n",
      "-------------- Início do folder dfdc_train_part_25 --------------\n",
      "dfdc_train_part_28: 0.00%...\n",
      "dfdc_train_part_28: 25.00%...\n",
      "dfdc_train_part_28: 50.00%...\n",
      "dfdc_train_part_28: 75.00%...\n",
      "dfdc_train_part_28: 100.00%...\n",
      "Tempo para a conclusão do diretório: 32:10 min\n",
      "-------------- Início do folder dfdc_train_part_27 --------------\n",
      "dfdc_train_part_3: 0.00%...\n",
      "dfdc_train_part_3: 25.00%...\n",
      "dfdc_train_part_3: 50.00%...\n",
      "dfdc_train_part_3: 75.00%...\n",
      "dfdc_train_part_3: 100.00%...\n",
      "Tempo para a conclusão do diretório: 21:49 min\n",
      "-------------- Início do folder dfdc_train_part_15 --------------\n",
      "dfdc_train_part_16: 0.00%...\n",
      "dfdc_train_part_16: 25.00%...\n",
      "dfdc_train_part_16: 50.00%...\n",
      "dfdc_train_part_16: 75.00%...\n",
      "dfdc_train_part_16: 100.00%...\n",
      "Tempo para a conclusão do diretório: 32:55 min\n",
      "-------------- Início do folder dfdc_train_part_21 --------------\n",
      "dfdc_train_part_24: 0.00%...\n",
      "dfdc_train_part_24: 25.00%...\n",
      "dfdc_train_part_24: 50.00%...\n",
      "dfdc_train_part_24: 75.00%...\n",
      "dfdc_train_part_24: 100.00%...\n",
      "Tempo para a conclusão do diretório: 71:40 min\n",
      "-------------- Início do folder dfdc_train_part_34 --------------\n",
      "dfdc_train_part_4: 0.00%...\n",
      "dfdc_train_part_4: 25.00%...\n",
      "dfdc_train_part_4: 50.00%...\n",
      "dfdc_train_part_4: 75.00%...\n",
      "dfdc_train_part_4: 100.00%...\n",
      "Tempo para a conclusão do diretório: 30:40 min\n",
      "-------------- Início do folder dfdc_train_part_43 --------------\n",
      "dfdc_train_part_8: 0.00%...\n",
      "dfdc_train_part_8: 25.00%...\n",
      "dfdc_train_part_8: 50.00%...\n",
      "dfdc_train_part_8: 75.00%...\n",
      "Tempo para a conclusão do diretório: 30:30 min\n"
     ]
    }
   ],
   "source": [
    "PATH = './Kaggle Dataset/'\n",
    "CHECK_EVERY_FRAME = 15\n",
    "PADDING = 10\n",
    "SIZE = -1\n",
    "BATCH_SIZE = 20\n",
    "CHANNEL = None\n",
    "FOLDER = 'Faces Dataset'\n",
    "SIZE_FOLDER = 'no-resize-color'\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "for pick in pick_order:\n",
    "    folder_path = PATH + recent_folders[pick]\n",
    "    # Instaciamos uma objeto da classe Videos aplicado ao path obtido\n",
    "    videos = Videos(folder_path)\n",
    "    videos_generator = videos.getAllVideosPath()    \n",
    "    \n",
    "    print(\"-------------- Início do folder {} --------------\".format(folders[pick]))\n",
    "    videos_quantity = len(videos.video_files)\n",
    "    percentage = 25\n",
    "    print_every = int(videos_quantity / (100/percentage))\n",
    "    \n",
    "    init = time.time()\n",
    "    for n_video, VIDEO_DATA in enumerate(videos_generator):\n",
    "        \n",
    "        saveCropFaces(*VIDEO_DATA, \n",
    "                      batch_size=BATCH_SIZE, \n",
    "                      padding=PADDING, \n",
    "                      size=SIZE, \n",
    "                      check_every_frame=CHECK_EVERY_FRAME, \n",
    "                      channel=CHANNEL, \n",
    "                      folder=FOLDER,\n",
    "                      size_folder=SIZE_FOLDER)\n",
    "        \n",
    "        if n_video % print_every == 0:\n",
    "            print(\"{}: {:.2f}%...\".format(recent_folders[pick], round(n_video / videos_quantity * 100)))\n",
    "        \n",
    "        \n",
    "    end = time.time()\n",
    "    total = end - init\n",
    "    print(\"Tempo para a conclusão do diretório: {:.0f}:{:.0f} min\".format(int(total/60), total % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui o processo foi interrompido pois a quantidade total de imagens de rostos recortadas já superava o meio milhão, suficiente para rodar algumas redes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
